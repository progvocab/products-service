# **Kubernetes Deployment Strategies**  

When deploying applications in **Kubernetes**, choosing the right strategy ensures **zero downtime, rollback capabilities, and efficient resource utilization**. Below are the most commonly used deployment strategies.

---

## **1ï¸âƒ£ Rolling Update (Default)**
ğŸ”¹ **Gradually replaces old pods with new ones**  
ğŸ”¹ **No downtime**  
ğŸ”¹ Can be controlled using **maxSurge** and **maxUnavailable**  

### **ğŸ“Œ How It Works**
- New pods are gradually created while old ones are terminated.
- Ensures **zero downtime** by maintaining a minimum number of running instances.
- Suitable for **most applications** that can handle incremental updates.

### **ğŸ“Œ Example Deployment**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rolling-update-demo
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1        # Extra pod allowed during update
      maxUnavailable: 1  # Max pods that can be unavailable
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
      - name: demo-container
        image: my-app:v2  # New version of the app
```
âœ… **Best For:** Most applications, ensuring smooth updates without downtime.  
âŒ **Drawback:** If something goes wrong, rolling back can take time.

---

## **2ï¸âƒ£ Blue-Green Deployment**
ğŸ”¹ **Two identical environments (Blue & Green)**  
ğŸ”¹ **Instant rollback if issues occur**  
ğŸ”¹ **Uses a Service to switch traffic between versions**  

### **ğŸ“Œ How It Works**
1. **Blue** represents the live version.
2. **Green** is deployed with the new version.
3. Traffic is switched from **Blue** to **Green** using a **Kubernetes Service**.
4. If something goes wrong, traffic can be reverted to **Blue**.

### **ğŸ“Œ Example Deployment**
```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app-green  # Switch to new version dynamically
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8080
```
âœ… **Best For:** Critical applications requiring zero downtime and easy rollback.  
âŒ **Drawback:** Requires **double resources**, which can be costly.



### **Canary Deployment**
- **Deploys new version to a small subset of users**  
- **Progressively increases rollout if stable**  
- Uses **labels and selectors** to manage traffic  


1. Deploy **new version** to a small percentage of users.
2. Monitor for failures (e.g., using Prometheus).
3. Gradually shift more traffic to the new version.
4. If issues arise, roll back easily.


```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: canary-deployment
spec:
  replicas: 2
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: my-app-container
        image: my-app:v2  # Canary version
```
**Best For:** Applications requiring gradual exposure to minimize risks.  
**Drawback:** Needs **traffic management (e.g., Istio, Nginx Ingress)** for routing.



### **Recreate Deployment**
 **Stops old version before deploying the new one**  
 **Downtime occurs during deployment**  
 **Simple and resource-efficient**  


1. All existing **pods are terminated**.
2. New pods with the updated version are created.
3. There is a **brief downtime** between stopping old pods and starting new ones.

### **ğŸ“Œ Example Deployment**
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: recreate-deployment
spec:
  strategy:
    type: Recreate  # Stops old pods before creating new ones
  selector:
    matchLabels:
      app: demo
  template:
    metadata:
      labels:
        app: demo
    spec:
      containers:
      - name: demo-container
        image: my-app:v2
```
 **Best For:** Stateless applications where downtime is acceptable.  
 **Drawback:** Causes **downtime**, making it unsuitable for high-availability services.



### **A/B Testing Deployment**
 - **Routes traffic based on user attributes (e.g., location, device, user group)**  
- **Requires advanced traffic management (e.g., Istio, Nginx Ingress)**  
- **Can test different features for different users**  

### **ğŸ“Œ How It Works**
1. Users are split into different groups (e.g., **Group A gets v1, Group B gets v2**).
2. Routing happens **at the load balancer level**.
3. Telemetry data is analyzed to decide the success of the new version.

âœ… **Best For:** AI-based features, feature flag testing, and gradual rollouts.  
âŒ **Drawback:** Needs **advanced traffic control tools**.

---

## **Comparison Table**

| Strategy          | **Downtime** | **Rollback** | **Resource Usage** | **Use Case** |
|------------------|------------|-------------|----------------|-------------|
| Rolling Update   | No         | Slow rollback | Efficient | Most applications |
| Blue-Green      | No         | Instant | High (duplicate resources) | Critical applications |
| Canary          | No         | Fast | Moderate | Gradual rollouts with monitoring |
| Recreate        | Yes        | Fast | Low | Simple apps where downtime is okay |
| A/B Testing     | No         | Fast | High (requires traffic splitting) | Feature flag testing |

---

### **Which Deployment Strategy Should You Use?**
- **For zero-downtime, safe updates â†’ Rolling Update**
- **For instant rollback & critical apps â†’ Blue-Green**
- **For gradual testing & exposure â†’ Canary**
- **For simple, non-critical apps â†’ Recreate**
- **For user-based experiments â†’ A/B Testing**



A Kubernetes Deployment manages application updates using different rollout strategies such as Rolling, Recreate (all-at-once), Blue-Green, and Canary. In the Recreate strategy, Kubernetes terminates all existing Pods before starting new ones. Rolling updates replace Pods graduallyâ€”new Pods come up first, receive traffic once healthy, and then old Pods are taken down. In Blue-Green deployments, an entire new set of Pods (green) is created alongside the existing set (blue), and traffic is switched to green only after verification. Canary releases create a small subset of new Pods and route only a small percentage of traffic to them initially; if they perform well, Kubernetes increments traffic until all requests move to the new version.