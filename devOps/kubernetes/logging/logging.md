### **üîπ Integrating Logging & Monitoring for OIDC-Enabled Kubernetes (Kind + AWS Cognito)**
To ensure observability in your **OIDC-enabled Kind cluster**, we‚Äôll integrate:  
‚úÖ **Prometheus** for metrics collection  
‚úÖ **Grafana** for visualization  
‚úÖ **AWS CloudWatch** for centralized logs  

---

## **üîπ 1. Deploy Prometheus & Grafana in Kubernetes**
### **1Ô∏è‚É£ Install Prometheus & Grafana Using Helm**
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
helm install prometheus prometheus-community/kube-prometheus-stack
```

### **2Ô∏è‚É£ Expose Prometheus & Grafana**
```bash
kubectl port-forward svc/prometheus-kube-prometheus-prometheus 9090
kubectl port-forward svc/prometheus-grafana 3000
```
- **Prometheus Dashboard**: `http://localhost:9090`  
- **Grafana Dashboard**: `http://localhost:3000`  
  - **Username:** `admin`
  - **Password:** `prom-operator`

### **3Ô∏è‚É£ Add Prometheus Data Source in Grafana**
- Go to **Settings ‚Üí Data Sources**
- Select **Prometheus**
- Set **URL**: `http://prometheus-kube-prometheus-prometheus:9090`
- **Save & Test**

---

## **üîπ 2. Send Kubernetes Logs to AWS CloudWatch**
### **1Ô∏è‚É£ Deploy Fluent Bit for Log Collection**
```bash
helm install fluent-bit stable/fluent-bit \
  --set cloudWatch.region=<AWS_REGION> \
  --set cloudWatch.logGroup=Kubernetes-Logs
```

### **2Ô∏è‚É£ Verify Logs in AWS CloudWatch**
```bash
aws logs describe-log-groups --query "logGroups[*].logGroupName"
aws logs tail Kubernetes-Logs --follow
```

---

## **üîπ 3. Monitor OIDC Authentication & RBAC Logs**
### **1Ô∏è‚É£ Enable API Server Auditing**
Modify your **Kind cluster config**:
```yaml
apiServer:
  extraArgs:
    audit-log-path: "/var/log/kubernetes/audit.log"
    audit-log-maxage: "30"
    audit-log-maxsize: "100"
    audit-log-maxbackup: "5"
```

### **2Ô∏è‚É£ Query Authentication Logs in CloudWatch**
```bash
aws logs filter-log-events --log-group-name Kubernetes-Logs --filter-pattern '{ $.user.username = "kind-user" }'
```

---

## **üîπ Summary**
‚úÖ **Prometheus & Grafana for monitoring**  
‚úÖ **AWS CloudWatch for Kubernetes logs**  
‚úÖ **Auditing OIDC authentication & RBAC events**  

Would you like **alerts for failed logins & security incidents?** üöÄ

### **üîπ Setting Up Alerts for Failed Logins & Security Incidents in Kubernetes**  
We will configure **alerting mechanisms** for:  
‚úÖ **Failed OIDC logins** (Authentication failures)  
‚úÖ **Unauthorized Kubernetes API access** (RBAC violations)  
‚úÖ **Unusual activity** (e.g., too many login attempts)

---

## **üîπ 1. Configure Prometheus Alerting**
### **1Ô∏è‚É£ Create Alert Rules for Failed Logins**
- Failed logins can be detected using **OIDC authentication logs** from API Server.
- Create a Prometheus rule to **detect excessive 401/403 responses**.

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: failed-login-alerts
spec:
  groups:
  - name: failed-login-rules
    rules:
    - alert: FailedOIDCLogin
      expr: rate(apiserver_request_total{code="401"}[5m]) > 5
      for: 2m
      labels:
        severity: warning
      annotations:
        summary: "Multiple failed OIDC login attempts detected"
        description: "More than 5 failed logins in 5 minutes. Possible brute force attack."
```
**Apply the Rule**  
```bash
kubectl apply -f failed-login-alerts.yaml
```

---

## **üîπ 2. Set Up Alertmanager to Send Notifications**
### **1Ô∏è‚É£ Install Alertmanager via Helm**
```bash
helm install alertmanager prometheus-community/prometheus \
  --set alertmanager.enabled=true
```

### **2Ô∏è‚É£ Configure AlertManager to Send Email/Slack Alerts**
Create `alertmanager-config.yaml`:
```yaml
global:
  resolve_timeout: 5m
route:
  receiver: "slack-alerts"
  repeat_interval: 30m
receivers:
  - name: "slack-alerts"
    slack_configs:
      - api_url: "https://hooks.slack.com/services/XXXXXXXXX"
        channel: "#security-alerts"
        title: "OIDC Login Alert"
        text: "{{ .CommonAnnotations.summary }}"
```
**Apply Configuration**  
```bash
kubectl apply -f alertmanager-config.yaml
```

---

## **üîπ 3. Monitor Unauthorized API Access via AWS CloudWatch**
### **1Ô∏è‚É£ Create a CloudWatch Alarm for Unauthorized Access**
Create a metric filter for **403 Forbidden responses** in the API server logs:
```bash
aws logs put-metric-filter --log-group-name Kubernetes-Logs \
  --filter-name UnauthorizedAccessFilter \
  --metric-transformations metricName=UnauthorizedAccess,metricNamespace=Kubernetes,metricValue=1 \
  --filter-pattern '{ $.code = "403" }'
```

### **2Ô∏è‚É£ Set Up an Alarm for Too Many Unauthorized Requests**
```bash
aws cloudwatch put-metric-alarm --alarm-name "TooManyUnauthorizedRequests" \
  --metric-name "UnauthorizedAccess" --namespace "Kubernetes" \
  --statistic Sum --period 300 --threshold 10 --comparison-operator GreaterThanThreshold \
  --evaluation-periods 1 --alarm-actions <SNS_TOPIC_ARN>
```

---

## **üîπ 4. (Optional) Block Suspicious IPs Using Network Policies**
If brute force attacks are detected, you can block the source IP in **Kubernetes Network Policies**:

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: block-suspicious-ips
spec:
  podSelector: {}
  ingress:
  - from:
    - ipBlock:
        cidr: "192.168.1.100/32"
```
**Apply Policy:**  
```bash
kubectl apply -f block-suspicious-ips.yaml
```

---

## **üîπ Summary**
‚úÖ **Prometheus & AlertManager detect failed logins**  
‚úÖ **Slack/email alerts for security incidents**  
‚úÖ **CloudWatch alarm for unauthorized API access**  
‚úÖ **Kubernetes Network Policies to block suspicious IPs**  

Would you like **IAM-based access control for Kubernetes with AWS IAM Roles?** üöÄ